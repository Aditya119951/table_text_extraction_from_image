{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813b785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Function to calculate regression metrics\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n = len(y_true)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - 1)\n",
    "    return {\n",
    "        'Metric': ['MAE', 'MSE', 'RMSE', 'R2', 'Adjusted R2'],\n",
    "        'Value': [mae, mse, rmse, r2, adj_r2]\n",
    "    }\n",
    "\n",
    "# Function to calculate classification metrics\n",
    "def calculate_classification_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    gini = 2 * auc - 1\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Metric': ['Precision', 'Recall', 'F1-Score','AUC ROC Score', 'GINI'],\n",
    "        'Value': [precision, recall, f1, auc, gini]\n",
    "    }\n",
    "\n",
    "    return metrics, confusion\n",
    "\n",
    "# Function to calculate business metrics\n",
    "def calculate_business_metrics(y_true, probabilities, amount, gdr_threshold):\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'probabilities': probabilities,\n",
    "        'amount': amount\n",
    "    })\n",
    "    df = df.sort_values(by='probabilities', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df['cum_1s'] = df['y_true'].cumsum()\n",
    "    df['cum_amount_1s'] = df['amount'] * df['y_true']\n",
    "    df['cum_0s'] = (~df['y_true'].astype(bool)).cumsum()\n",
    "\n",
    "    df['TDR'] = df['cum_1s'] / df['y_true'].sum()\n",
    "    df['VDR'] = df['cum_amount_1s'].cumsum() / (df['amount'] * df['y_true']).sum()\n",
    "    df['GDR'] = df['cum_0s'] / (~df['y_true'].astype(bool)).sum()\n",
    "\n",
    "    selected_row = df[df['GDR'] <= gdr_threshold].iloc[-1]\n",
    "\n",
    "    return {\n",
    "        'Metric': ['TDR', 'VDR'],\n",
    "        'Value': [selected_row['TDR'], selected_row['VDR']]\n",
    "    }\n",
    "\n",
    "# Function to save regression results to Excel\n",
    "def save_regression_results_to_excel(results, dataset_type):\n",
    "    file_name = 'regression_results.xlsx'\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        workbook = load_workbook(file_name)\n",
    "    except FileNotFoundError:\n",
    "        # If not found, create a new workbook and remove the default sheet\n",
    "        workbook = Workbook()\n",
    "        if 'Sheet' in workbook.sheetnames:\n",
    "            del workbook['Sheet']\n",
    "\n",
    "    # Check if the sheet for the dataset type already exists, and create if not\n",
    "    if dataset_type not in workbook.sheetnames:\n",
    "        workbook.create_sheet(title=dataset_type)\n",
    "    \n",
    "    # Select the appropriate sheet\n",
    "    sheet = workbook[dataset_type]\n",
    "\n",
    "    # Append the header only if it's a new sheet\n",
    "    if sheet.max_row == 1:\n",
    "        sheet.append(['Metric', 'Value'])\n",
    "\n",
    "    # Append the new results\n",
    "    for metric, value in zip(results['Metric'], results['Value']):\n",
    "        sheet.append([metric, value])\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(file_name)\n",
    "    print(f'Regression results saved to {file_name}, sheet: {dataset_type}')\n",
    "\n",
    "# Function to save classification results to Excel\n",
    "def save_classification_results_to_excel(results, confusion, business_metrics, dataset_type):\n",
    "    file_name = 'classification_results.xlsx'\n",
    "    try:\n",
    "        workbook = load_workbook(file_name)\n",
    "    except FileNotFoundError:\n",
    "        workbook = Workbook()\n",
    "        if 'Sheet' in workbook.sheetnames:\n",
    "            del workbook['Sheet']\n",
    "\n",
    "    if dataset_type not in workbook.sheetnames:\n",
    "        workbook.create_sheet(title=dataset_type)\n",
    "\n",
    "    sheet = workbook[dataset_type]\n",
    "\n",
    "    if sheet.max_row == 1:\n",
    "        sheet.append(['Metric', 'Value'])\n",
    "\n",
    "    if 'Metric' in results and 'Value' in results:\n",
    "        for metric, value in zip(results['Metric'], results['Value']):\n",
    "            sheet.append([metric, value])\n",
    "\n",
    "    if len(confusion) > 0:\n",
    "        sheet.append([])\n",
    "        sheet.append(['Confusion Matrix'])\n",
    "\n",
    "        confusion_df = pd.DataFrame(confusion, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "        header = [''] + confusion_df.columns.tolist()\n",
    "        sheet.append(header)\n",
    "\n",
    "        for idx, row in confusion_df.iterrows():\n",
    "            sheet.append([idx] + row.tolist())\n",
    "\n",
    "    if 'Metric' in business_metrics and 'Value' in business_metrics:\n",
    "        sheet.append([])\n",
    "        sheet.append(['Business Metrics'])\n",
    "\n",
    "        for metric, value in zip(business_metrics['Metric'], business_metrics['Value']):\n",
    "            sheet.append([metric, value])\n",
    "\n",
    "    workbook.save(file_name)\n",
    "    print(f'Classification results saved to {file_name}, sheet: {dataset_type}')\n",
    "\n",
    "# Main function for widget-based interface\n",
    "def create_widgets_for_metrics(dataset):\n",
    "    global current_dataset\n",
    "\n",
    "    dataset_type = widgets.Dropdown(\n",
    "        options=[('Select One', 'select_one'), ('Train', 'train'), ('Test', 'test')],\n",
    "        description='Dataset Type:',\n",
    "    )\n",
    "\n",
    "    def on_dataset_type_change(change):\n",
    "        global current_dataset\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        if change['new'] == 'train':\n",
    "            current_dataset = dataset.copy()\n",
    "            display(train_buttons)\n",
    "        elif change['new'] == 'test':\n",
    "            current_dataset = dataset.copy()\n",
    "            display(test_buttons)\n",
    "\n",
    "    dataset_type.observe(on_dataset_type_change, names='value')\n",
    "\n",
    "    regression_button = widgets.Button(description='Regression Metrics', tooltip=\"Generate metrics for regression tasks.\")\n",
    "    classification_button = widgets.Button(description='Classification Metrics', tooltip=\"Generate metrics for classification tasks.\")\n",
    "\n",
    "    def on_regression_button_clicked(b):\n",
    "        regression_button.style.button_color = 'lightblue'  # Highlight the selected button\n",
    "        classification_button.style.button_color = None  # Reset the other button color\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        display(regression_button, classification_button)  # Re-display the buttons\n",
    "        display(regression_selection)\n",
    "    \n",
    "    def on_classification_button_clicked(b):\n",
    "        classification_button.style.button_color = 'lightblue'  # Highlight the selected button\n",
    "        regression_button.style.button_color = None  # Reset the other button color\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        display(regression_button, classification_button)  # Re-display the buttons\n",
    "        display(classification_selection)\n",
    "\n",
    "    regression_button.on_click(on_regression_button_clicked)\n",
    "    classification_button.on_click(on_classification_button_clicked)\n",
    "    \n",
    "    regression_target = widgets.Dropdown(\n",
    "    options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "    description='Actual:',\n",
    "    )\n",
    "    regression_prediction = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Predicted:',\n",
    "    )\n",
    "\n",
    "    def generate_regression_report(b):\n",
    "        y_true = current_dataset[regression_target.value]\n",
    "        y_pred = current_dataset[regression_prediction.value]\n",
    "        results = calculate_regression_metrics(y_true, y_pred)\n",
    "        display(pd.DataFrame(results))\n",
    "        save_regression_results_to_excel(results, 'train' if dataset_type.value == 'train' else 'test')\n",
    "\n",
    "    regression_generate_button = widgets.Button(description='Generate Regression Report', tooltip=\"Generate the regression report.\")\n",
    "    regression_generate_button.on_click(generate_regression_report)\n",
    "\n",
    "    regression_selection = widgets.VBox([regression_target, regression_prediction, regression_generate_button])\n",
    "\n",
    "    classification_actual = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Actual:',\n",
    "    )\n",
    "    classification_prediction_prob = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Predicted Probabilities:',\n",
    "    )\n",
    "    classification_amount = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Amount:',\n",
    "    )\n",
    "\n",
    "    threshold_slider = widgets.FloatSlider(\n",
    "        value=0.5, min=0.0, max=1.0, step=0.01, description='Threshold:',\n",
    "    )\n",
    "\n",
    "    def generate_classification_report(b):\n",
    "        y_true = current_dataset[classification_actual.value]\n",
    "        probabilities = current_dataset[classification_prediction_prob.value]\n",
    "        amount = current_dataset[classification_amount.value]\n",
    "\n",
    "        threshold = threshold_slider.value\n",
    "        y_pred = (probabilities >= threshold).astype(int)\n",
    "\n",
    "        results, confusion = calculate_classification_metrics(y_true, y_pred)\n",
    "\n",
    "        display(widgets.HTML('<h4>Model Metrics</h4>'))\n",
    "        display(pd.DataFrame(results))\n",
    "        display(pd.DataFrame(confusion, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1']))\n",
    "\n",
    "        business_metrics = {'Metric': [], 'Value': []}  # Placeholder for business metrics\n",
    "\n",
    "        save_classification_results_to_excel(results, confusion, business_metrics, 'train' if dataset_type.value == 'train' else 'test')\n",
    "\n",
    "    classification_generate_button = widgets.Button(description='Generate Model Metrics', tooltip=\"Generate the model metrics report.\")\n",
    "    classification_generate_button.on_click(generate_classification_report)\n",
    "\n",
    "    gdr_slider = widgets.FloatSlider(\n",
    "        value=0.1, min=0.0, max=1.0, step=0.01, description='GDR:',\n",
    "    )\n",
    "\n",
    "    def generate_business_metrics(b):\n",
    "        y_true = current_dataset[classification_actual.value]\n",
    "        probabilities = current_dataset[classification_prediction_prob.value]\n",
    "        amount = current_dataset[classification_amount.value]\n",
    "\n",
    "        gdr_threshold = gdr_slider.value\n",
    "        business_metrics = calculate_business_metrics(y_true, probabilities, amount, gdr_threshold)\n",
    "\n",
    "        display(widgets.HTML('<h4>Business Metrics</h4>'))\n",
    "        display(pd.DataFrame(business_metrics))\n",
    "\n",
    "        save_classification_results_to_excel({}, [], business_metrics, 'train' if dataset_type.value == 'train' else 'test')\n",
    "\n",
    "    business_generate_button = widgets.Button(description='Generate Business Metrics', tooltip=\"Generate the business metrics report.\")\n",
    "    business_generate_button.on_click(generate_business_metrics)\n",
    "\n",
    "    classification_selection = widgets.VBox([\n",
    "        classification_actual,\n",
    "        classification_prediction_prob,\n",
    "        classification_amount,\n",
    "        threshold_slider,\n",
    "        widgets.Label(\"If unsure, use the default threshold of 0.5.\"),\n",
    "        classification_generate_button,\n",
    "        gdr_slider,\n",
    "        business_generate_button\n",
    "    ])\n",
    "\n",
    "    train_buttons = widgets.VBox([regression_button, classification_button])\n",
    "    test_buttons = widgets.VBox([regression_button, classification_button])\n",
    "\n",
    "\n",
    "    display(dataset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faaabd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "df = pd.DataFrame({\n",
    "    'r_actual': [3, 5, 2, 7, 8],\n",
    "    'r_predicted': [2.5, 5.1, 2.0, 7.2, 7.8],\n",
    "    'c_actual': [1, 0, 0, 1, 1],\n",
    "    'c_predicted': [0.78, 0.39, 0.21, 0.63, 0.15],\n",
    "    'trans_amt': [200, 300, 400, 100, 700]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8e9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a150bee9c34558801e693017e6b79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset Type:', index=2, options=(('Select One', 'select_one'), ('Train', 'train'), ('Te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de659519540640228ec5dbc8c2b5ee0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Regression Metrics', style=ButtonStyle(), tooltip='Generate metrics for regression tasks.'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cabe5e6cdf481dae5902cf01919722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classification Metrics', style=ButtonStyle(button_color='lightblue'), tooltip='Generate me…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6925b535804a42abd282321902504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Actual:', index=2, options=('r_actual', 'r_predicted', 'c_actual', 'c_pre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dff9211086c4ed3b09d72a429c64a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4>Model Metrics</h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUC ROC Score</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GINI</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Metric     Value\n",
       "0      Precision  1.000000\n",
       "1         Recall  0.333333\n",
       "2       F1-Score  0.500000\n",
       "3  AUC ROC Score  0.666667\n",
       "4           GINI  0.333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0            2            0\n",
       "Actual 1            2            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results saved to classification_results.xlsx, sheet: test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb86497d52145ff8cacd67f6ff73e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4>Business Metrics</h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TDR</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VDR</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric     Value\n",
       "0    TDR  0.666667\n",
       "1    VDR  0.300000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results saved to classification_results.xlsx, sheet: test\n"
     ]
    }
   ],
   "source": [
    "create_widgets_for_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92686637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
