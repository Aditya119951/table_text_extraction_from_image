{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "813b785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Function to calculate regression metrics\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n = len(y_true)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - 1)\n",
    "    return {\n",
    "        'Metric': ['MAE', 'MSE', 'RMSE', 'R2', 'Adjusted R2'],\n",
    "        'Value': [mae, mse, rmse, r2, adj_r2]\n",
    "    }\n",
    "\n",
    "# Function to calculate classification metrics\n",
    "def calculate_classification_metrics(y_true, y_pred, amount):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    gini = 2 * auc - 1\n",
    "    tdr = np.sum(y_pred * y_true) / np.sum(y_true)\n",
    "    vdr = np.sum(y_pred * amount) / np.sum(amount)\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Metric': ['Precision', 'Recall', 'F1-Score', 'GINI', 'TDR', 'VDR'],\n",
    "        'Value': [precision, recall, f1, gini, tdr, vdr]\n",
    "    }\n",
    "\n",
    "    return metrics, confusion\n",
    "\n",
    "# Function to display messages\n",
    "def display_message(message):\n",
    "    print(message)\n",
    "\n",
    "# Helper function to check if a column is suitable for regression (continuous data)\n",
    "def is_suitable_for_regression(column_data):\n",
    "    unique_values = column_data.nunique()\n",
    "    return unique_values > 2  # Simple check to ensure it's continuous data (more than 2 unique values)\n",
    "\n",
    "# Helper function to check if a column is suitable for classification (binary or categorical data)\n",
    "def is_suitable_for_classification(column_data):\n",
    "    unique_values = column_data.nunique()\n",
    "    return unique_values == 2  # For binary classification, only 2 unique values are expected\n",
    "\n",
    "\n",
    "# Function to save regression results to Excel\n",
    "def save_regression_results_to_excel(results, dataset_type):\n",
    "    file_name = 'regression_results.xlsx'\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        workbook = load_workbook(file_name)\n",
    "    except FileNotFoundError:\n",
    "        # If not found, create a new workbook and remove the default sheet\n",
    "        workbook = Workbook()\n",
    "        if 'Sheet' in workbook.sheetnames:\n",
    "            del workbook['Sheet']\n",
    "\n",
    "    # Check if the sheet for the dataset type already exists, and create if not\n",
    "    if dataset_type not in workbook.sheetnames:\n",
    "        workbook.create_sheet(title=dataset_type)\n",
    "    \n",
    "    # Select the appropriate sheet\n",
    "    sheet = workbook[dataset_type]\n",
    "\n",
    "    # Append the header only if it's a new sheet\n",
    "    if sheet.max_row == 1:\n",
    "        sheet.append(['Metric', 'Value'])\n",
    "\n",
    "    # Append the new results\n",
    "    for metric, value in zip(results['Metric'], results['Value']):\n",
    "        sheet.append([metric, value])\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(file_name)\n",
    "    print(f'Regression results saved to {file_name}, sheet: {dataset_type}')\n",
    "\n",
    "# Function to save classification results to Excel\n",
    "def save_classification_results_to_excel(results, confusion, dataset_type):\n",
    "    file_name = 'classification_results.xlsx'\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        workbook = load_workbook(file_name)\n",
    "    except FileNotFoundError:\n",
    "        # If not found, create a new workbook and remove the default sheet\n",
    "        workbook = Workbook()\n",
    "        if 'Sheet' in workbook.sheetnames:\n",
    "            del workbook['Sheet']\n",
    "\n",
    "    # Check if the sheet for the dataset type already exists, and create if not\n",
    "    if dataset_type not in workbook.sheetnames:\n",
    "        workbook.create_sheet(title=dataset_type)\n",
    "    \n",
    "    # Select the appropriate sheet\n",
    "    sheet = workbook[dataset_type]\n",
    "\n",
    "    # Append the header only if it's a new sheet\n",
    "    if sheet.max_row == 1:\n",
    "        sheet.append(['Metric', 'Value'])\n",
    "\n",
    "    # Append the metrics\n",
    "    for metric, value in zip(results['Metric'], results['Value']):\n",
    "        sheet.append([metric, value])\n",
    "\n",
    "    # Add a section for the confusion matrix\n",
    "    sheet.append([])\n",
    "    sheet.append(['Confusion Matrix'])\n",
    "\n",
    "    # Convert the confusion matrix DataFrame to a format that includes column and index labels\n",
    "    confusion_df = pd.DataFrame(confusion, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "    \n",
    "    # Write the header row for the confusion matrix\n",
    "    header = [''] + confusion_df.columns.tolist()\n",
    "    sheet.append(header)\n",
    "\n",
    "    # Write each row of the confusion matrix with the index label\n",
    "    for idx, row in confusion_df.iterrows():\n",
    "        sheet.append([idx] + row.tolist())\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(file_name)\n",
    "    print(f'Classification results saved to {file_name}, sheet: {dataset_type}')\n",
    "\n",
    "\n",
    "# Main function for widget-based interface\n",
    "def create_widgets_for_metrics(dataset):\n",
    "    global current_dataset\n",
    "\n",
    "    dataset_type = widgets.Dropdown(\n",
    "        options=[('Select One', 'select_one'), ('Train', 'train'), ('Test', 'test')],\n",
    "        description='Dataset Type:',\n",
    "    )\n",
    "\n",
    "    def on_dataset_type_change(change):\n",
    "        global current_dataset\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        if change['new'] == 'train':\n",
    "            current_dataset = dataset.copy()\n",
    "            display(train_buttons)\n",
    "        elif change['new'] == 'test':\n",
    "            current_dataset = dataset.copy()\n",
    "            display(test_buttons)\n",
    "\n",
    "    dataset_type.observe(on_dataset_type_change, names='value')\n",
    "\n",
    "    regression_button = widgets.Button(description='Regression Metrics', tooltip=\"Generate metrics for regression tasks.\")\n",
    "    classification_button = widgets.Button(description='Classification Metrics', tooltip=\"Generate metrics for classification tasks.\")\n",
    "\n",
    "    def on_regression_button_clicked(b):\n",
    "        regression_button.style.button_color = 'lightblue'  # Highlight the selected button\n",
    "        classification_button.style.button_color = None  # Reset the other button color\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        display(regression_button, classification_button)  # Re-display the buttons\n",
    "        display(regression_selection)\n",
    "\n",
    "    def on_classification_button_clicked(b):\n",
    "        classification_button.style.button_color = 'lightblue'  # Highlight the selected button\n",
    "        regression_button.style.button_color = None  # Reset the other button color\n",
    "        clear_output(wait=True)\n",
    "        display(dataset_type)\n",
    "        display(regression_button, classification_button)  # Re-display the buttons\n",
    "        display(classification_selection)\n",
    "\n",
    "    regression_button.on_click(on_regression_button_clicked)\n",
    "    classification_button.on_click(on_classification_button_clicked)\n",
    "\n",
    "    regression_target = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Actual:',\n",
    "    )\n",
    "    regression_prediction = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Predicted:',\n",
    "    )\n",
    "\n",
    "    def generate_regression_report(b):\n",
    "        if not (is_suitable_for_regression(current_dataset[regression_target.value]) and \n",
    "                is_suitable_for_regression(current_dataset[regression_prediction.value])):\n",
    "            display_message(\"These metrics are not applicable to regression problems.\")\n",
    "            return\n",
    "        y_true = current_dataset[regression_target.value]\n",
    "        y_pred = current_dataset[regression_prediction.value]\n",
    "        results = calculate_regression_metrics(y_true, y_pred)\n",
    "        display(pd.DataFrame(results))\n",
    "        save_regression_results_to_excel(results, 'train' if dataset_type.value == 'train' else 'test')\n",
    "\n",
    "    regression_generate_button = widgets.Button(description='Generate Regression Report', tooltip=\"Generate the regression report.\")\n",
    "    regression_generate_button.on_click(generate_regression_report)\n",
    "\n",
    "    regression_selection = widgets.VBox([regression_target, regression_prediction, regression_generate_button])\n",
    "\n",
    "    classification_actual = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Actual:',\n",
    "    )\n",
    "    classification_prediction = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Predicted:',\n",
    "    )\n",
    "    classification_amount = widgets.Dropdown(\n",
    "        options=[col for col in dataset.columns if dataset[col].dtype in ['int64', 'float64']],\n",
    "        description='Amount:',\n",
    "    )\n",
    "\n",
    "    def generate_classification_report(b):\n",
    "        if not (is_suitable_for_classification(current_dataset[classification_actual.value]) and \n",
    "                is_suitable_for_classification(current_dataset[classification_prediction.value])):\n",
    "            display_message(\"These metrics are not applicable to classification problems.\")\n",
    "            return\n",
    "        y_true = current_dataset[classification_actual.value]\n",
    "        y_pred = current_dataset[classification_prediction.value]\n",
    "        amount = current_dataset[classification_amount.value]\n",
    "        results, confusion = calculate_classification_metrics(y_true, y_pred, amount)\n",
    "        display(pd.DataFrame(results))\n",
    "        display(pd.DataFrame(confusion, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1']))\n",
    "        save_classification_results_to_excel(results, confusion, 'train' if dataset_type.value == 'train' else 'test')\n",
    "\n",
    "    classification_generate_button = widgets.Button(description='Generate Classification Report', tooltip=\"Generate the classification report.\")\n",
    "    classification_generate_button.on_click(generate_classification_report)\n",
    "\n",
    "    classification_selection = widgets.VBox([classification_actual, classification_prediction, classification_amount, classification_generate_button])\n",
    "\n",
    "    train_buttons = widgets.VBox([regression_button, classification_button])\n",
    "    test_buttons = widgets.VBox([regression_button, classification_button])\n",
    "\n",
    "    display(dataset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faaabd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "df = pd.DataFrame({\n",
    "    'r_actual': [3, 5, 2, 7, 8],\n",
    "    'r_predicted': [2.5, 5.1, 2.0, 7.2, 7.8],\n",
    "    'c_actual': [1, 0, 0, 1, 1],\n",
    "    'c_predicted': [0, 0, 1, 1, 1],\n",
    "    'trans_amt': [200, 300, 400, 100, 700]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab8e9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c0ded115184005b7f7d399ed674f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset Type:', index=2, options=(('Select One', 'select_one'), ('Train', 'train'), ('Te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73484dfc0ee4421b8dc06c662be62c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Regression Metrics', style=ButtonStyle(), tooltip='Generate metrics for regression tasks.'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa7faa784a45cda542c93b2c3904ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classification Metrics', style=ButtonStyle(button_color='lightblue'), tooltip='Generate me…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a319e1e2ae584f10b26208df7867c38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Actual:', index=2, options=('r_actual', 'r_predicted', 'c_actual', 'c_pre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GINI</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TDR</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VDR</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0  Precision  0.666667\n",
       "1     Recall  0.666667\n",
       "2   F1-Score  0.666667\n",
       "3       GINI  0.166667\n",
       "4        TDR  0.666667\n",
       "5        VDR  0.705882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0            1            1\n",
       "Actual 1            1            2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_widgets_for_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92686637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
